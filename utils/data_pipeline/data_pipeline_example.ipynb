{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information please refer [TFDS-PIPELINE Examples](https://github.com/SB-Jr/tldr_tensorflow/tree/master/v2/TFDS_PIPELINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main focus of the ETL pipeline is to make sure that the GPU and CPU are working in sync and that none of the devices are in idle state and so that we get the most out of the hardware we have. The job of CPU is to do all the ETL process and the GPU's task is take the data from the ETL pipline and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the preprocessing of the data is done by the CPU, it often can become the botlleneck. This can be avoided with a good efficient pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching\n",
    "\n",
    "One method to create a efficient ETL pipeline is to use Data caching. Datasets/Tensors can be cached in 2 ways:\n",
    "- Cachin in memory\n",
    "- Cachine in Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching in memory\n",
    "\n",
    "Here the caching takes place in the RAM. \n",
    "we use `tf.data.Dataset.cache()` to cache the dataset so that the need to do pre-processing again and again for each epoch is not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching in Disk\n",
    "\n",
    "Here we use the `tf.data.Dataset.cache(filename='<file name here>')` and can then store the cache on disk if the data is too big to e stored in the memory(RAM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel APIs\n",
    "\n",
    "\n",
    "The main APIs in `tf.data.Dataset` that we can use to take the advantage of parallelism to get the most out of our hardware are:\n",
    "- map\n",
    "- prefetch\n",
    "- interleave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTOTUNE\n",
    "\n",
    "Most of the parallel APIs will need us to give values to parameters based on our system configuraion. These values can be hardcoded in most of the casses but in case of Cloud architectures, where the system are scalled all the time eihter horizontally or vertically, with changing system configuration, we cant keep chaging the code to keep providing the hardocded data. \n",
    "\n",
    "This is where the Autotune API helps us. We can set almost all the variables or parameters with Autotune so that the proper values to get the max utilization of the resources are carried by the TF itself.\n",
    "\n",
    "```python\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map\n",
    "\n",
    "Most often we need to perform preprocessing like augmentation on the data before it is passed further towards the model. This can be a very expensive taks if we dont utilize all the cores of the CPU to parallelize the process.\n",
    "eg:\n",
    "```python\n",
    "def augmentation(features):\n",
    "    x = tf.image.random_flip_left_right(features['image'])\n",
    "    x = tf.image.random_flip_up_down(x)\n",
    "    x = tf.image.random_brightness(x, max_dedlta=0.1)\n",
    "    x = tf.image.random_saturation(x, lower=0.75, upper=1.5)\n",
    "    x = tf.image.random_hue(x, max_delta=0.15)\n",
    "    x = tf.image.random_contrast(x, lower=0.75, upper=1.5)\n",
    "    x = tf.image.resize(x, (224, 224))\n",
    "    image = x/255.0\n",
    "    return image, features['label']\n",
    "\n",
    "# load dataset\n",
    "dataset = tfds.load(cats_dogs, split=tfds.Split.TRAIN)\n",
    "# how many cores of CPU do u have?\n",
    "cores = 8\n",
    "augmented_dataset = dataset.map(augmentation, num_parallel_calls=cores-1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prefetch\n",
    "\n",
    "We can use prefetch so that the data preprocessing for the next epoch can be done by the CPU while the epoch is being executed on the GPU. This way the CPU and GPU are being used simultaneouslt at the same time thus increasing the system throughput.\n",
    "\n",
    "eg:\n",
    "```python\n",
    "preped_dataset = dataset.map(augmentation_fn).prefetch(AUTOTUNE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inteleave\n",
    "\n",
    "We can also try to optimize the data extraction so that the data that has been extracted( or loaded into memeory or is ready for further use) can be preprocessed so that the CPU resources are used properly. So basically here we are trying to parallelize the I/O and preprocessing(map) operation.\n",
    "\n",
    "eg:\n",
    "```python\n",
    "files = tf.data.Dataset.list_files('regex to cover all files')\n",
    "\n",
    "num_parallel_reads = 4\n",
    "\n",
    "dataset = files.interleave(\n",
    "    tf.data.TFRecordDataset,  # map function\n",
    "    cycle_length=num_parallel_reads, \n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T10:58:51.299338Z",
     "iopub.status.busy": "2020-12-17T10:58:51.298244Z",
     "iopub.status.idle": "2020-12-17T10:58:53.382111Z",
     "shell.execute_reply": "2020-12-17T10:58:53.381476Z",
     "shell.execute_reply.started": "2020-12-17T10:58:51.299191Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import multiprocessing\n",
    "import tensorflow_datasets as tfds\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:17:14.781985Z",
     "iopub.status.busy": "2020-12-17T11:17:14.781359Z",
     "iopub.status.idle": "2020-12-17T11:17:14.796357Z",
     "shell.execute_reply": "2020-12-17T11:17:14.794261Z",
     "shell.execute_reply.started": "2020-12-17T11:17:14.781911Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_layer = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_tensor=input_layer,\n",
    "                                                   weights='imagenet',\n",
    "                                                   include_top=False)\n",
    "    base_model.trainable = False\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=input_layer, outputs=x)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T10:58:54.460281Z",
     "iopub.status.busy": "2020-12-17T10:58:54.459659Z",
     "iopub.status.idle": "2020-12-17T11:00:44.196973Z",
     "shell.execute_reply": "2020-12-17T11:00:44.194992Z",
     "shell.execute_reply.started": "2020-12-17T10:58:54.460208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset cats_vs_dogs/4.0.0 (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /home/sbjr/my_workspace/tldr_tensorflow/v2/TFDS_PIPELINE/dataset/cats_vs_dogs/4.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b03675576b4e5384a3f8597f618b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', layout=Layout(width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5c41cc416d4b3ca5915585e9275f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', layout=Layout(width='20px'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6671df9c2542659042039ba57bfdde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eabe121443b42cd80676ecc1eb90867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:1738 images were corrupted and were skipped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling and writing examples to /home/sbjr/my_workspace/tldr_tensorflow/v2/TFDS_PIPELINE/dataset/cats_vs_dogs/4.0.0.incompleteQ6RU67/cats_vs_dogs-train.tfrecord\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415eb285234e4a17a37b36b3f6c60dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23262.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cats_vs_dogs downloaded and prepared to /home/sbjr/my_workspace/tldr_tensorflow/v2/TFDS_PIPELINE/dataset/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'cats_vs_dogs'\n",
    "filePath = f'{os.getcwd()}/dataset'\n",
    "dataset, info = tfds.load(name=dataset_name, split=tfds.Split.TRAIN, with_info=True, data_dir=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:00:44.287265Z",
     "iopub.status.busy": "2020-12-17T11:00:44.286158Z",
     "iopub.status.idle": "2020-12-17T11:00:44.296860Z",
     "shell.execute_reply": "2020-12-17T11:00:44.295001Z",
     "shell.execute_reply.started": "2020-12-17T11:00:44.287184Z"
    }
   },
   "outputs": [],
   "source": [
    "def preproces(features):\n",
    "    image = features['image']\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = image/255.0\n",
    "    return image, features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:00:44.300591Z",
     "iopub.status.busy": "2020-12-17T11:00:44.300117Z",
     "iopub.status.idle": "2020-12-17T11:00:44.373909Z",
     "shell.execute_reply": "2020-12-17T11:00:44.373191Z",
     "shell.execute_reply.started": "2020-12-17T11:00:44.300531Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = dataset.map(preproces).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:19:14.527462Z",
     "iopub.status.busy": "2020-12-17T11:19:14.526868Z",
     "iopub.status.idle": "2020-12-17T11:23:34.531399Z",
     "shell.execute_reply": "2020-12-17T11:23:34.529400Z",
     "shell.execute_reply.started": "2020-12-17T11:19:14.527393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 µs, sys: 2 µs, total: 23 µs\n",
      "Wall time: 47.7 µs\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "727/727 [==============================] - 51s 70ms/step - loss: 0.0628 - acc: 0.9780\n",
      "Epoch 2/5\n",
      "727/727 [==============================] - 51s 70ms/step - loss: 0.0415 - acc: 0.9858\n",
      "Epoch 3/5\n",
      "727/727 [==============================] - 50s 69ms/step - loss: 0.0362 - acc: 0.9877\n",
      "Epoch 4/5\n",
      "727/727 [==============================] - 51s 71ms/step - loss: 0.0326 - acc: 0.9893\n",
      "Epoch 5/5\n",
      "727/727 [==============================] - 51s 70ms/step - loss: 0.0299 - acc: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efc0f9ca2e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(train_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Process - Pipeline Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interleave\n",
    "\n",
    "As we have already downlaoded the dataset we will now parallely read the data so as to efficiently use the resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:29:48.260418Z",
     "iopub.status.busy": "2020-12-17T11:29:48.259769Z",
     "iopub.status.idle": "2020-12-17T11:29:48.413381Z",
     "shell.execute_reply": "2020-12-17T11:29:48.411590Z",
     "shell.execute_reply.started": "2020-12-17T11:29:48.260340Z"
    }
   },
   "outputs": [],
   "source": [
    "file_pattern = f'{os.getcwd()}/dataset/{dataset_name}/{info.version}/{dataset_name}-train.tfrecord*'\n",
    "files = tf.data.Dataset.list_files(file_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:29:49.046163Z",
     "iopub.status.busy": "2020-12-17T11:29:49.045528Z",
     "iopub.status.idle": "2020-12-17T11:29:49.059056Z",
     "shell.execute_reply": "2020-12-17T11:29:49.056592Z",
     "shell.execute_reply.started": "2020-12-17T11:29:49.046086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:29:49.883539Z",
     "iopub.status.busy": "2020-12-17T11:29:49.882930Z",
     "iopub.status.idle": "2020-12-17T11:29:49.967575Z",
     "shell.execute_reply": "2020-12-17T11:29:49.965400Z",
     "shell.execute_reply.started": "2020-12-17T11:29:49.883464Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_parallel = files.interleave(\n",
    "    tf.data.TFRecordDataset,\n",
    "    cycle_length=4,\n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prase and Decode\n",
    "\n",
    "\n",
    "The dataset files in TFRecords format are present in serialized format. We need to parse the data to load them properly as images and labels. For this\n",
    "- we need to define the structure of each record\n",
    "- itterate over the dataset parallely to generate the parsed data i.e. images and corresponding label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:29:51.476666Z",
     "iopub.status.busy": "2020-12-17T11:29:51.476033Z",
     "iopub.status.idle": "2020-12-17T11:29:51.485723Z",
     "shell.execute_reply": "2020-12-17T11:29:51.483662Z",
     "shell.execute_reply.started": "2020-12-17T11:29:51.476590Z"
    }
   },
   "outputs": [],
   "source": [
    "format_description = {\n",
    "    'image': tf.io.FixedLenFeature((), tf.string, ''), # '' is the default value to be assigned if it is empty\n",
    "    'label': tf.io.FixedLenFeature((), tf.int64, -1) # we are converting the label into int in place of string here with default value -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:29:52.179348Z",
     "iopub.status.busy": "2020-12-17T11:29:52.178739Z",
     "iopub.status.idle": "2020-12-17T11:29:52.191153Z",
     "shell.execute_reply": "2020-12-17T11:29:52.188971Z",
     "shell.execute_reply.started": "2020-12-17T11:29:52.179275Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_tfrecord(record):\n",
    "    row = tf.io.parse_single_example(record, format_description)\n",
    "    \n",
    "    image = tf.io.decode_jpeg(row['image'], channels=3)\n",
    "    label = row['label']\n",
    "    \n",
    "    # preprocessing the image\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = image/255.0\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:29:52.990365Z",
     "iopub.status.busy": "2020-12-17T11:29:52.989753Z",
     "iopub.status.idle": "2020-12-17T11:29:53.000961Z",
     "shell.execute_reply": "2020-12-17T11:29:52.998145Z",
     "shell.execute_reply.started": "2020-12-17T11:29:52.990293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "print(cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:29:53.630303Z",
     "iopub.status.busy": "2020-12-17T11:29:53.629662Z",
     "iopub.status.idle": "2020-12-17T11:29:53.708961Z",
     "shell.execute_reply": "2020-12-17T11:29:53.706540Z",
     "shell.execute_reply.started": "2020-12-17T11:29:53.630228Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_parallel = train_dataset_parallel.map(parse_tfrecord, num_parallel_calls=cores) # here we used cores as num_parallel_calls in place of AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cache the dataset\n",
    "\n",
    "This is for better performance. Mostly useful if we have a big model and multiple epochs taking over the same dataset again and again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:29:56.798927Z",
     "iopub.status.busy": "2020-12-17T11:29:56.797996Z",
     "iopub.status.idle": "2020-12-17T11:29:56.834692Z",
     "shell.execute_reply": "2020-12-17T11:29:56.832542Z",
     "shell.execute_reply.started": "2020-12-17T11:29:56.798805Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_parallel = train_dataset_parallel.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Process - Actual loading of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:29:58.035623Z",
     "iopub.status.busy": "2020-12-17T11:29:58.034994Z",
     "iopub.status.idle": "2020-12-17T11:29:58.073138Z",
     "shell.execute_reply": "2020-12-17T11:29:58.070988Z",
     "shell.execute_reply.started": "2020-12-17T11:29:58.035550Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_parallel = train_dataset_parallel.shuffle(1024).batch(32)\n",
    "train_dataset_parallel = train_dataset_parallel.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:37:36.966726Z",
     "iopub.status.busy": "2020-12-17T11:37:36.966110Z",
     "iopub.status.idle": "2020-12-17T11:56:49.010762Z",
     "shell.execute_reply": "2020-12-17T11:56:48.997308Z",
     "shell.execute_reply.started": "2020-12-17T11:37:36.966645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "727/727 [==============================] - 279s 383ms/step - loss: 0.0630 - acc: 0.9773\n",
      "Epoch 2/5\n",
      "727/727 [==============================] - 423s 581ms/step - loss: 0.0415 - acc: 0.9857\n",
      "Epoch 3/5\n",
      "727/727 [==============================] - 112s 154ms/step - loss: 0.0365 - acc: 0.9871\n",
      "Epoch 4/5\n",
      "727/727 [==============================] - 248s 342ms/step - loss: 0.0325 - acc: 0.9886\n",
      "Epoch 5/5\n",
      "727/727 [==============================] - 81s 112ms/step - loss: 0.0298 - acc: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efa91f5e0d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parallel = create_model()\n",
    "model_parallel.fit(train_dataset_parallel, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
